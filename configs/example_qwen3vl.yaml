seed: 42

data:
  path: data/raw/processed_adapter_data.jsonl
  batch_size: 16
  num_workers: 0
  max_len: 1024

model:
  backbone: qwen3vl
  model_name: /ytech_m2v5_hdd/workspace/kling_mm/libozhou/Model/Qwen3-VL-8B-te-ours-language-model
  layers_to_select: -1
  select_all_layers_or_not: false
  adapter: attn
  proj_dim: 1024
  num_layers: 2
  use_rope: true
  temperature: 0.1
  max_len: 1024
  norm_type: layer_norm

optimizer:
  lr: 1.0e-05
  weight_decay: 1.0e-05

trainer:
  output: runs_multi_epoch/qwen3vl-ours-last1-2layers
  epochs: 1
  accumulation_steps: 1
  warmup_epochs: 0.0
  amp: false
  save_every_steps: 100
  num_max_saved: 25
  lr_schedule: constant

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a797908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmu_mllm_hdd/yangsihan05/miniconda3/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# Requires transformers>=4.51.0\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/ytech_m2v5_hdd/workspace/kling_mm/yangsihan05/models/Qwen/Qwen3-Embedding-8B', padding_side='left')\n",
    "model = AutoModel.from_pretrained('/ytech_m2v5_hdd/workspace/kling_mm/yangsihan05/models/Qwen/Qwen3-Embedding-8B')\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving.\n",
    "# model = AutoModel.from_pretrained('Qwen/Qwen3-Embedding-8B', attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16).cuda()\n",
    "\n",
    "max_length = 8192\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722b6ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (embed_tokens): Embedding(151665, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-35): 36 x Qwen3DecoderLayer(\n",
       "      (self_attn): Qwen3Attention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "      )\n",
       "      (mlp): Qwen3MLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "        (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "  (rotary_emb): Qwen3RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9095e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each query must come with a one-sentence instruction that describes the task\n",
    "task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "\n",
    "queries = [\n",
    "    get_detailed_instruct(task, 'What is the capital of China?'),\n",
    "    get_detailed_instruct(task, 'Explain gravity')\n",
    "]\n",
    "# No need to add instruction for retrieval documents\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\"\n",
    "]\n",
    "input_texts = queries + documents\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153e16ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:What is the capital of China?',\n",
       " 'Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:Explain gravity',\n",
       " 'The capital of China is Beijing.',\n",
       " 'Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30245c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151643, 151643, 151643, 151643,    641,   1235,     25,  16246,    264,\n",
       "           3482,   2711,   3239,     11,  17179,   9760,  46769,    429,   4226,\n",
       "            279,   3239,    198,   2859,     25,   3838,    374,    279,   6722,\n",
       "            315,   5616,     30, 151643],\n",
       "        [151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,    641,\n",
       "           1235,     25,  16246,    264,   3482,   2711,   3239,     11,  17179,\n",
       "           9760,  46769,    429,   4226,    279,   3239,    198,   2859,     25,\n",
       "            840,  20772,  23249, 151643],\n",
       "        [151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643,    785,   6722,    315,   5616,\n",
       "            374,  26549,     13, 151643],\n",
       "        [ 38409,    374,    264,   5344,    429,  60091,   1378,  12866,   6974,\n",
       "           1817,   1008,     13,   1084,   6696,   4680,    311,   6961,   6171,\n",
       "            323,    374,   8480,    369,    279,   7203,    315,  32875,   2163,\n",
       "            279,   7015,     13, 151643]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(\n",
    "    input_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "batch_dict.to(model.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a27ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch_dict, output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3293bdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"hidden_states\"].__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ed9a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a166f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4096])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4b2babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7493014931678772, 0.07506485283374786], [0.08795969188213348, 0.6318402886390686]]\n"
     ]
    }
   ],
   "source": [
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T)\n",
    "print(scores.tolist())\n",
    "# [[0.7493016123771667, 0.0750647559762001], [0.08795969933271408, 0.6318399906158447]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988c8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"FLASH_ATTENTION_2_DISABLED\"] = \"1\"\n",
    "os.environ[\"DISABLE_FLASH_ATTN\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "282a9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:40<00:00, 20.16s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModel.from_pretrained(\"/ytech_m2v5_hdd/workspace/kling_mm/yangsihan05/models/jinaai/jina-embeddings-v4\", trust_remote_code=True, torch_dtype=torch.float16)\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"غروب جميل على الشاطئ\",  # Arabic\n",
    "    \"海滩上美丽的日落\",  # Chinese\n",
    "    \"Un beau coucher de soleil sur la plage\",  # French\n",
    "    \"Ein wunderschöner Sonnenuntergang am Strand\",  # German\n",
    "    \"Ένα όμορφο ηλιοβασίλεμα πάνω από την παραλία\",  # Greek\n",
    "    \"समुद्र तट पर एक खूबसूरत सूर्यास्त\",  # Hindi\n",
    "    \"Un bellissimo tramonto sulla spiaggia\",  # Italian\n",
    "    \"浜辺に沈む美しい夕日\",  # Japanese\n",
    "    \"해변 위로 아름다운 일몰\",  # Korean\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "457a6721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForFeatureExtraction(\n",
       "  (base_model): LoraModel(\n",
       "    (model): JinaEmbeddingsV4Model(\n",
       "      (model): Qwen2_5_VLModel(\n",
       "        (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
       "          (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
       "            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "          )\n",
       "          (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
       "          (blocks): ModuleList(\n",
       "            (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
       "              (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "              (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "              (attn): Qwen2_5_VLVisionSdpaAttention(\n",
       "                (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "                (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (mlp): Qwen2_5_VLMLP(\n",
       "                (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (merger): Qwen2_5_VLPatchMerger(\n",
       "            (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=5120, out_features=2048, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (language_model): Qwen2_5_VLTextModel(\n",
       "          (embed_tokens): Embedding(151936, 2048)\n",
       "          (layers): ModuleList(\n",
       "            (0-35): 36 x Qwen2_5_VLDecoderLayer(\n",
       "              (self_attn): Qwen2_5_VLSdpaAttention(\n",
       "                (q_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=256, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=256, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "              )\n",
       "              (mlp): Qwen2MLP(\n",
       "                (gate_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.MultiAdapterLinear(\n",
       "                  (base_layer): Linear(in_features=11008, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                      (text-matching): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                      (code): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): ModuleDict(\n",
       "                      (retrieval): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                      (text-matching): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                      (code): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "            )\n",
       "          )\n",
       "          (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "          (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       "      (multi_vector_projector): lora.MultiAdapterLinear(\n",
       "        (base_layer): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): ModuleDict(\n",
       "            (retrieval): Linear(in_features=2048, out_features=32, bias=False)\n",
       "            (text-matching): Linear(in_features=2048, out_features=32, bias=False)\n",
       "            (code): Linear(in_features=2048, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): ModuleDict(\n",
       "            (retrieval): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (text-matching): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (code): Linear(in_features=32, out_features=128, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af433ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts...: 100%|██████████| 3/3 [00:00<00:00, 12.63it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"غروب جميل على الشاطئd海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # Arabic\n",
    "    \"海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # Chinese\n",
    "    \"Un beau coucher de soleil sur la plage海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # French\n",
    "    \"Ein wunderschöner Sonnenuntergang am Strand海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # German\n",
    "    \"Ένα όμορφο ηλιοβασίλεμα πάνω από την παραλία海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # Greek\n",
    "    \"समुद्र तट पर एक खूबसूरत सूर्यास्त海滩上美丽的日落\",  # Hindi\n",
    "    \"Un bellissimo tramonto sulla spiaggia海滩上美丽的日落海滩上美丽的日落\",  # Italian\n",
    "    \"浜辺に沈む美しい夕日海滩上美丽的日落\",  # Japanese\n",
    "    \"해변 위로 아름다운 일몰海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # Korean\n",
    "    \"غروب جميل على الشاطئ海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # Arabic\n",
    "    \"海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落\",  # Chinese\n",
    "    \"Un beau coucher de soleil sur la海滩上美丽的日落海滩上美丽的日落海滩上美丽的日落 plage\",  # French\n",
    "    \"Ein wunderschöner Sonnenuntergang海滩上美丽的日落 am Strand\",  # German\n",
    "    \"Ένα όμορφο ηλιοβασίλεμα πάν海滩上美丽的日落ω από την παραλία\",  # Greek\n",
    "    \"समुद्र तट पर एक खूबसूर海滩上美丽的日落海滩上美丽的日落त सूर्यास्त\",  # Hindi\n",
    "    \"Un bellissimo tramonto sulla spiaggia\",  # Italian\n",
    "    \"浜辺に沈む美しい夕日\",  # Japanese\n",
    "    \"해변 \",  # Korean\n",
    "]\n",
    "\n",
    "text_embeddings = model.encode_text(texts=texts, \n",
    "                                    task=\"text-matching\",\n",
    "                                    prompt_name=None,\n",
    "                                    return_multivector=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "957725f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = model.encode_text(\n",
    "    texts=[\"Overview of climate change impacts on coastal cities\"],\n",
    "    task=\"retrieval\",\n",
    "    prompt_name=\"query\",\n",
    ")\n",
    "\n",
    "# Encode passage (text)\n",
    "passage_embeddings = model.encode_text(\n",
    "    texts=[\n",
    "        \"Climate change has led to rising sea levels, increased frequency of extreme weather events...\"\n",
    "    ],\n",
    "    task=\"retrieval\",\n",
    "    prompt_name=\"passage\",\n",
    ")\n",
    "\n",
    "# Encode image/document\n",
    "image_embeddings = model.encode_image(\n",
    "    images=[\"https://i.ibb.co/nQNGqL0/beach1.jpg\"],\n",
    "    task=\"retrieval\",\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# 2. Text Matching Task\n",
    "# ========================\n",
    "texts = [\n",
    "    \"غروب جميل على الشاطئ\",  # Arabic\n",
    "    \"海滩上美丽的日落\",  # Chinese\n",
    "    \"Un beau coucher de soleil sur la plage\",  # French\n",
    "    \"Ein wunderschöner Sonnenuntergang am Strand\",  # German\n",
    "    \"Ένα όμορφο ηλιοβασίλεμα πάνω από την παραλία\",  # Greek\n",
    "    \"समुद्र तट पर एक खूबसूरत सूर्यास्त\",  # Hindi\n",
    "    \"Un bellissimo tramonto sulla spiaggia\",  # Italian\n",
    "    \"浜辺に沈む美しい夕日\",  # Japanese\n",
    "    \"해변 위로 아름다운 일몰\",  # Korean\n",
    "]\n",
    "\n",
    "text_embeddings = model.encode_text(texts=texts, task=\"text-matching\")\n",
    "\n",
    "# ========================\n",
    "# 3. Code Understanding Task\n",
    "# ========================\n",
    "\n",
    "# Encode query\n",
    "query_embedding = model.encode_text(\n",
    "    texts=[\"Find a function that prints a greeting message to the console\"],\n",
    "    task=\"code\",\n",
    "    prompt_name=\"query\",\n",
    ")\n",
    "\n",
    "# Encode code\n",
    "code_embeddings = model.encode_text(\n",
    "    texts=[\"def hello_world():\\n    print('Hello, World!')\"],\n",
    "    task=\"code\",\n",
    "    prompt_name=\"passage\",\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# 4. Use multivectors\n",
    "# ========================\n",
    "\n",
    "multivector_embeddings = model.encode_text(\n",
    "    texts=texts,\n",
    "    task=\"retrieval\",\n",
    "    prompt_name=\"query\",\n",
    "    return_multivector=True,\n",
    ")\n",
    "\n",
    "images = [\"https://i.ibb.co/nQNGqL0/beach1.jpg\", \"https://i.ibb.co/r5w8hG8/beach2.jpg\"]\n",
    "multivector_image_embeddings = model.encode_image(\n",
    "    images=images,\n",
    "    task=\"retrieval\",\n",
    "    return_multivector=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
